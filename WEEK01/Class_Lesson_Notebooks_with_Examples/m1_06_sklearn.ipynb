{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# sklearn Machine Learning Examples\n",
        "\n",
        "This notebook demonstrates classification, regression, dimensionality reduction, and clustering using sklearn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Classification Example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install scikit-learn numpy matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import VarianceThreshold  # Correct import\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "  Downloading pandas-3.0.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.4.2-cp313-cp313-win_amd64.whl.metadata (6.6 kB)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.8.0-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.8-cp313-cp313-win_amd64.whl.metadata (52 kB)\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cindy\\anaconda3\\envs\\ac\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Collecting tzdata (from pandas)\n",
            "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting scipy>=1.10.0 (from scikit-learn)\n",
            "  Downloading scipy-1.17.0-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
            "Collecting joblib>=1.3.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.61.1-cp313-cp313-win_amd64.whl.metadata (116 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\cindy\\anaconda3\\envs\\ac\\lib\\site-packages (from matplotlib) (25.0)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Downloading pillow-12.1.0-cp313-cp313-win_amd64.whl.metadata (9.0 kB)\n",
            "Collecting pyparsing>=3 (from matplotlib)\n",
            "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\cindy\\anaconda3\\envs\\ac\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pandas-3.0.0-cp313-cp313-win_amd64.whl (9.7 MB)\n",
            "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 1.3/9.7 MB 6.9 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 2.4/9.7 MB 6.2 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 3.9/9.7 MB 6.3 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 5.5/9.7 MB 6.4 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 6.6/9.7 MB 6.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 8.1/9.7 MB 6.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  9.7/9.7 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.7/9.7 MB 6.3 MB/s  0:00:01\n",
            "Downloading numpy-2.4.2-cp313-cp313-win_amd64.whl (12.3 MB)\n",
            "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 1.6/12.3 MB 7.6 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 3.1/12.3 MB 7.6 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 4.5/12.3 MB 7.4 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 5.8/12.3 MB 6.9 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 7.1/12.3 MB 6.8 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 8.4/12.3 MB 6.6 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 9.7/12.3 MB 6.6 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 11.0/12.3 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.1/12.3 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.3/12.3 MB 6.3 MB/s  0:00:01\n",
            "Downloading scikit_learn-1.8.0-cp313-cp313-win_amd64.whl (8.0 MB)\n",
            "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 1.0/8.0 MB 5.3 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 2.6/8.0 MB 6.3 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 3.9/8.0 MB 6.4 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 5.5/8.0 MB 6.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 7.3/8.0 MB 6.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.0/8.0 MB 6.6 MB/s  0:00:01\n",
            "Downloading matplotlib-3.10.8-cp313-cp313-win_amd64.whl (8.1 MB)\n",
            "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 1.3/8.1 MB 6.9 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 2.6/8.1 MB 6.7 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 3.9/8.1 MB 6.5 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 5.5/8.1 MB 6.6 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 6.8/8.1 MB 6.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.1/8.1 MB 6.5 MB/s  0:00:01\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl (226 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.61.1-cp313-cp313-win_amd64.whl (2.3 MB)\n",
            "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
            "   ---------------------- ----------------- 1.3/2.3 MB 5.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.3/2.3 MB 5.6 MB/s  0:00:00\n",
            "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
            "Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl (73 kB)\n",
            "Downloading pillow-12.1.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
            "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
            "   ------- -------------------------------- 1.3/7.0 MB 6.6 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 2.6/7.0 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 3.9/7.0 MB 6.3 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 5.5/7.0 MB 6.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.0/7.0 MB 6.6 MB/s  0:00:01\n",
            "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
            "Downloading scipy-1.17.0-cp313-cp313-win_amd64.whl (36.3 MB)\n",
            "   ---------------------------------------- 0.0/36.3 MB ? eta -:--:--\n",
            "   - -------------------------------------- 1.0/36.3 MB 5.9 MB/s eta 0:00:07\n",
            "   -- ------------------------------------- 2.6/36.3 MB 6.3 MB/s eta 0:00:06\n",
            "   ---- ----------------------------------- 3.9/36.3 MB 6.6 MB/s eta 0:00:05\n",
            "   ------ --------------------------------- 5.5/36.3 MB 6.9 MB/s eta 0:00:05\n",
            "   ------- -------------------------------- 7.1/36.3 MB 7.0 MB/s eta 0:00:05\n",
            "   --------- ------------------------------ 8.7/36.3 MB 6.9 MB/s eta 0:00:05\n",
            "   ----------- ---------------------------- 10.2/36.3 MB 7.0 MB/s eta 0:00:04\n",
            "   ------------ --------------------------- 11.5/36.3 MB 7.0 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 13.1/36.3 MB 7.0 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 14.7/36.3 MB 6.9 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 15.5/36.3 MB 6.8 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 16.5/36.3 MB 6.6 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 17.6/36.3 MB 6.5 MB/s eta 0:00:03\n",
            "   -------------------- ------------------- 18.4/36.3 MB 6.3 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 19.4/36.3 MB 6.2 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 20.4/36.3 MB 6.1 MB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 21.8/36.3 MB 6.1 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 23.3/36.3 MB 6.1 MB/s eta 0:00:03\n",
            "   --------------------------- ------------ 24.9/36.3 MB 6.2 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 26.5/36.3 MB 6.3 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 28.3/36.3 MB 6.4 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 29.9/36.3 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 31.5/36.3 MB 6.5 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 33.3/36.3 MB 6.5 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 34.6/36.3 MB 6.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  36.2/36.3 MB 6.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 36.3/36.3 MB 6.4 MB/s  0:00:05\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
            "Installing collected packages: tzdata, threadpoolctl, pyparsing, pillow, numpy, kiwisolver, joblib, fonttools, cycler, scipy, pandas, contourpy, scikit-learn, matplotlib, seaborn\n",
            "\n",
            "   ----------------------------------------  0/15 [tzdata]\n",
            "   ----------------------------------------  0/15 [tzdata]\n",
            "   ----------------------------------------  0/15 [tzdata]\n",
            "   ----------------------------------------  0/15 [tzdata]\n",
            "   ----------------------------------------  0/15 [tzdata]\n",
            "   ----- ----------------------------------  2/15 [pyparsing]\n",
            "   ----- ----------------------------------  2/15 [pyparsing]\n",
            "   -------- -------------------------------  3/15 [pillow]\n",
            "   -------- -------------------------------  3/15 [pillow]\n",
            "   -------- -------------------------------  3/15 [pillow]\n",
            "   -------- -------------------------------  3/15 [pillow]\n",
            "   -------- -------------------------------  3/15 [pillow]\n",
            "   -------- -------------------------------  3/15 [pillow]\n",
            "   -------- -------------------------------  3/15 [pillow]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ---------- -----------------------------  4/15 [numpy]\n",
            "   ------------- --------------------------  5/15 [kiwisolver]\n",
            "   ---------------- -----------------------  6/15 [joblib]\n",
            "   ---------------- -----------------------  6/15 [joblib]\n",
            "   ---------------- -----------------------  6/15 [joblib]\n",
            "   ---------------- -----------------------  6/15 [joblib]\n",
            "   ---------------- -----------------------  6/15 [joblib]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------ ---------------------  7/15 [fonttools]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   ------------------------ ---------------  9/15 [scipy]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   -------------------------- ------------- 10/15 [pandas]\n",
            "   ----------------------------- ---------- 11/15 [contourpy]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   -------------------------------- ------- 12/15 [scikit-learn]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ---------------------------------- ----- 13/15 [matplotlib]\n",
            "   ------------------------------------- -- 14/15 [seaborn]\n",
            "   ------------------------------------- -- 14/15 [seaborn]\n",
            "   ------------------------------------- -- 14/15 [seaborn]\n",
            "   ------------------------------------- -- 14/15 [seaborn]\n",
            "   ---------------------------------------- 15/15 [seaborn]\n",
            "\n",
            "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 joblib-1.5.3 kiwisolver-1.4.9 matplotlib-3.10.8 numpy-2.4.2 pandas-3.0.0 pillow-12.1.0 pyparsing-3.3.2 scikit-learn-1.8.0 scipy-1.17.0 seaborn-0.13.2 threadpoolctl-3.6.0 tzdata-2025.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn matplotlib seaborn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "selector = VarianceThreshold(threshold=0.0)\n",
        "X_temp = df.drop('Survived', axis=1)\n",
        "selector.fit(X_temp)\n",
        "selected_features = X_temp.columns[selector.get_support()]\n",
        "df = df[list(selected_features) + ['Survived']]\n",
        "\n",
        "correlation_matrix = df.drop('Survived', axis=1).corr().abs()\n",
        "upper_triangle = correlation_matrix.where(\n",
        "    np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
        ")\n",
        "high_corr_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]\n",
        "df = df.drop(columns=high_corr_features)\n",
        "\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "lr_pred = lr_model.predict(X_test_scaled)\n",
        "lr_pred_proba = lr_model.predict_proba(X_test_scaled)[:, 1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "rf_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.5 Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = {\n",
        "    'Model': ['Logistic Regression', 'Random Forest'],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, lr_pred),\n",
        "        accuracy_score(y_test, rf_pred)\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, lr_pred),\n",
        "        precision_score(y_test, rf_pred)\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_test, lr_pred),\n",
        "        recall_score(y_test, rf_pred)\n",
        "    ],\n",
        "    'F1-Score': [\n",
        "        f1_score(y_test, lr_pred),\n",
        "        f1_score(y_test, rf_pred)\n",
        "    ],\n",
        "    'AUC-ROC': [\n",
        "        roc_auc_score(y_test, lr_pred_proba),\n",
        "        roc_auc_score(y_test, rf_pred_proba)\n",
        "    ]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(metrics)\n",
        "print(comparison_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Regression Example\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Data Loading and Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.feature_selection import VarianceThreshold  \n",
        "\n",
        "house_df = pd.read_csv('https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv')\n",
        "house_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_df = pd.get_dummies(house_df, columns=['ocean_proximity'], drop_first=True)\n",
        "\n",
        "house_df = house_df.select_dtypes(include=[np.number])\n",
        "\n",
        "selector_house = VarianceThreshold(threshold=0.0)\n",
        "X_temp_house = house_df.drop('median_house_value', axis=1)\n",
        "selector_house.fit(X_temp_house)\n",
        "selected_features_house = X_temp_house.columns[selector_house.get_support()]\n",
        "house_df = house_df[list(selected_features_house) + ['median_house_value']]\n",
        "\n",
        "correlation_matrix = house_df.drop('median_house_value', axis=1).corr().abs()\n",
        "upper_triangle = correlation_matrix.where(\n",
        "    np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
        ")\n",
        "high_corr_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]\n",
        "house_df = house_df.drop(columns=high_corr_features)\n",
        "\n",
        "X_house = house_df.drop('median_house_value', axis=1)\n",
        "y_house = house_df['median_house_value']\n",
        "X_train_house, X_test_house, y_train_house, y_test_house = train_test_split(\n",
        "    X_house, y_house, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 KNN Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "knn_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('power_transformer', PowerTransformer(method='yeo-johnson')),\n",
        "    ('knn', KNeighborsRegressor(n_neighbors=5))\n",
        "])\n",
        "\n",
        "knn_pipeline.fit(X_train_house, y_train_house)\n",
        "knn_pred = knn_pipeline.predict(X_test_house)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Linear Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_lr = X_train_house.fillna(X_train_house.median())\n",
        "X_test_lr = X_test_house.fillna(X_train_house.median())\n",
        "\n",
        "scaler_lr = StandardScaler()\n",
        "X_train_lr_scaled = scaler_lr.fit_transform(X_train_lr)\n",
        "X_test_lr_scaled = scaler_lr.transform(X_test_lr)\n",
        "\n",
        "correlation_matrix_lr = pd.DataFrame(X_train_lr_scaled).corr().abs()\n",
        "upper_triangle_lr = correlation_matrix_lr.where(\n",
        "    np.triu(np.ones(correlation_matrix_lr.shape), k=1).astype(bool)\n",
        ")\n",
        "high_corr_features_lr = [column for column in upper_triangle_lr.columns if any(upper_triangle_lr[column] > 0.95)]\n",
        "X_train_lr_scaled = pd.DataFrame(X_train_lr_scaled).drop(columns=high_corr_features_lr).values\n",
        "X_test_lr_scaled = pd.DataFrame(X_test_lr_scaled).drop(columns=high_corr_features_lr).values\n",
        "\n",
        "lr_reg_model = LinearRegression()\n",
        "lr_reg_model.fit(X_train_lr_scaled, y_train_house)\n",
        "lr_reg_pred = lr_reg_model.predict(X_test_lr_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "regression_metrics = {\n",
        "    'Model': ['KNN Regression', 'Linear Regression'],\n",
        "    'RMSE': [\n",
        "        np.sqrt(mean_squared_error(y_test_house, knn_pred)),\n",
        "        np.sqrt(mean_squared_error(y_test_house, lr_reg_pred))\n",
        "    ],\n",
        "    'MAE': [\n",
        "        mean_absolute_error(y_test_house, knn_pred),\n",
        "        mean_absolute_error(y_test_house, lr_reg_pred)\n",
        "    ],\n",
        "    'R2': [\n",
        "        r2_score(y_test_house, knn_pred),\n",
        "        r2_score(y_test_house, lr_reg_pred)\n",
        "    ],\n",
        "    'MAPE': [\n",
        "        mean_absolute_percentage_error(y_test_house, knn_pred),\n",
        "        mean_absolute_percentage_error(y_test_house, lr_reg_pred)\n",
        "    ]\n",
        "}\n",
        "\n",
        "regression_comparison_df = pd.DataFrame(regression_metrics)\n",
        "print(regression_comparison_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Discussion: are these a good models?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. PCA with Normalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca_df = house_df.copy()\n",
        "X_pca = pca_df.drop('median_house_value', axis=1)\n",
        "X_pca = X_pca.fillna(X_pca.median())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Normalization and PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler_pca = StandardScaler()\n",
        "X_pca_scaled = scaler_pca.fit_transform(X_pca)\n",
        "\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca_transformed = pca.fit_transform(X_pca_scaled)\n",
        "\n",
        "print(f\"Original features: {X_pca_scaled.shape[1]}\")\n",
        "print(f\"PCA components (95% variance): {X_pca_transformed.shape[1]}\")\n",
        "print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Variance Explained Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca_2d = PCA(n_components=2)\n",
        "X_pca_2d = pca_2d.fit_transform(X_pca_scaled)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "axes[0].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], alpha=0.6, s=30)\n",
        "axes[0].set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]:.2%} variance)')\n",
        "axes[0].set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]:.2%} variance)')\n",
        "axes[0].set_title('PCA - First Two Principal Components')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n",
        "axes[0].axvline(x=0, color='k', linestyle='-', linewidth=0.5)\n",
        "\n",
        "n_components_to_show = min(10, len(pca.explained_variance_ratio_))\n",
        "axes[1].bar(range(1, n_components_to_show + 1), \n",
        "            pca.explained_variance_ratio_[:n_components_to_show])\n",
        "axes[1].set_xlabel('Principal Component')\n",
        "axes[1].set_ylabel('Explained Variance Ratio')\n",
        "axes[1].set_title('Explained Variance by Component')\n",
        "axes[1].set_xticks(range(1, n_components_to_show + 1))\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "cumsum_var = np.cumsum(pca.explained_variance_ratio_[:n_components_to_show])\n",
        "ax2 = axes[1].twinx()\n",
        "ax2.plot(range(1, n_components_to_show + 1), cumsum_var, 'r-', marker='o', label='Cumulative')\n",
        "ax2.set_ylabel('Cumulative Explained Variance', color='r')\n",
        "ax2.tick_params(axis='y', labelcolor='r')\n",
        "ax2.axhline(y=0.95, color='r', linestyle='--', alpha=0.5, label='95% threshold')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Variance explained by PC1: {pca_2d.explained_variance_ratio_[0]:.4f}\")\n",
        "print(f\"Variance explained by PC2: {pca_2d.explained_variance_ratio_[1]:.4f}\")\n",
        "print(f\"Total variance (first 2 components): {pca_2d.explained_variance_ratio_.sum():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. K-Means Clustering with Elbow Method\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.feature_selection import VarianceThreshold  \n",
        "\n",
        "kmeans_df = house_df.copy()\n",
        "X_kmeans = kmeans_df.drop('median_house_value', axis=1)\n",
        "X_kmeans = X_kmeans.fillna(X_kmeans.median())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_kmeans = X_kmeans.select_dtypes(include=[np.number])\n",
        "\n",
        "selector_km = VarianceThreshold(threshold=0.0)\n",
        "selector_km.fit(X_kmeans)\n",
        "selected_features_km = X_kmeans.columns[selector_km.get_support()]\n",
        "X_kmeans = X_kmeans[selected_features_km]\n",
        "\n",
        "correlation_matrix_km = X_kmeans.corr().abs()\n",
        "upper_triangle_km = correlation_matrix_km.where(\n",
        "    np.triu(np.ones(correlation_matrix_km.shape), k=1).astype(bool)\n",
        ")\n",
        "high_corr_features_km = [column for column in upper_triangle_km.columns if any(upper_triangle_km[column] > 0.95)]\n",
        "X_kmeans = X_kmeans.drop(columns=high_corr_features_km)\n",
        "\n",
        "scaler_km = StandardScaler()\n",
        "transformer_km = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "X_kmeans_scaled = scaler_km.fit_transform(X_kmeans)\n",
        "X_kmeans_transformed = transformer_km.fit_transform(X_kmeans_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Elbow Method\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inertias = []\n",
        "K_range = range(1, 20)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_kmeans_transformed)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(K_range, inertias, marker='o')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Final K-Means Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimal_k = 2\n",
        "final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "clusters = final_kmeans.fit_predict(X_kmeans_transformed)\n",
        "\n",
        "silhouette_avg = silhouette_score(X_kmeans_transformed, clusters)\n",
        "print(f\"Optimal k: {optimal_k}\")\n",
        "print(f\"Silhouette Score: {silhouette_avg:.4f}\")\n",
        "print(f\"Cluster sizes: {np.bincount(clusters)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_kmeans['Cluster'] = clusters\n",
        "\n",
        "cluster_summary = X_kmeans.groupby('Cluster').agg(['mean', 'std', 'count'])\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"CLUSTER CHARACTERISTICS - Mean Values\")\n",
        "print(\"=\" * 80)\n",
        "for cluster_id in range(optimal_k):\n",
        "    print(f\"\\n--- Cluster {cluster_id} (n={np.sum(clusters == cluster_id)}) ---\")\n",
        "    cluster_means = X_kmeans[X_kmeans['Cluster'] == cluster_id].drop('Cluster', axis=1).mean()\n",
        "    print(cluster_means.sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cluster_profiles = X_kmeans.groupby('Cluster').mean()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "cluster_profiles_scaled = pd.DataFrame(\n",
        "    scaler.fit_transform(cluster_profiles.T).T,\n",
        "    index=cluster_profiles.index,\n",
        "    columns=cluster_profiles.columns\n",
        ")\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "sns.heatmap(cluster_profiles.T, annot=True, fmt='.2f', cmap='coolwarm', \n",
        "            center=0, ax=axes[0], cbar_kws={'label': 'Mean Value'})\n",
        "axes[0].set_title('Cluster Profiles - Raw Mean Values')\n",
        "axes[0].set_xlabel('Cluster')\n",
        "axes[0].set_ylabel('Features')\n",
        "\n",
        "# Heatmap 2: Standardized values (z-scores)\n",
        "sns.heatmap(cluster_profiles_scaled.T, annot=True, fmt='.2f', cmap='RdBu_r', \n",
        "            center=0, ax=axes[1], cbar_kws={'label': 'Z-Score'})\n",
        "axes[1].set_title('Cluster Profiles - Standardized Values (Z-scores)')\n",
        "axes[1].set_xlabel('Cluster')\n",
        "axes[1].set_ylabel('Features')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FEATURE IMPORTANCE FOR CLUSTERING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "feature_importance = cluster_profiles.var(axis=0).sort_values(ascending=False)\n",
        "print(\"\\nFeatures with highest variance across clusters (most discriminative):\")\n",
        "print(feature_importance)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DETAILED CLUSTER COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "comparison_df = pd.DataFrame()\n",
        "for i in range(optimal_k):\n",
        "    comparison_df[f'Cluster_{i}'] = X_kmeans[X_kmeans['Cluster'] == i].drop('Cluster', axis=1).mean()\n",
        "\n",
        "comparison_df = comparison_df.T\n",
        "print(comparison_df.round(2))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DISTINCTIVE FEATURES PER CLUSTER\")\n",
        "print(\"=\" * 80)\n",
        "for cluster_id in range(optimal_k):\n",
        "    print(f\"\\n--- Cluster {cluster_id} ---\")\n",
        "    cluster_data = cluster_profiles_scaled.loc[cluster_id].sort_values(ascending=False)\n",
        "    high_features = cluster_data[cluster_data > 1.5].index.tolist()\n",
        "    low_features = cluster_data[cluster_data < -1.5].index.tolist()\n",
        "    \n",
        "    if high_features:\n",
        "        print(f\"Notably HIGH: {', '.join(high_features)}\")\n",
        "    if low_features:\n",
        "        print(f\"Notably LOW: {', '.join(low_features)}\")\n",
        "    if not high_features and not low_features:\n",
        "        print(\"No extremely distinctive features (moderate values)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca_viz = PCA(n_components=2)\n",
        "X_pca_viz = pca_viz.fit_transform(X_kmeans_transformed)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "scatter = plt.scatter(X_pca_viz[:, 0], X_pca_viz[:, 1], \n",
        "                     c=clusters, cmap='viridis', alpha=0.6, s=50)\n",
        "plt.xlabel(f'PC1 ({pca_viz.explained_variance_ratio_[0]:.2%} variance)')\n",
        "plt.ylabel(f'PC2 ({pca_viz.explained_variance_ratio_[1]:.2%} variance)')\n",
        "plt.title('K-Means Clusters in PCA Space')\n",
        "plt.colorbar(scatter, label='Cluster', ticks=range(optimal_k))\n",
        "\n",
        "# Add cluster centers\n",
        "centers_pca = pca_viz.transform(final_kmeans.cluster_centers_)\n",
        "plt.scatter(centers_pca[:, 0], centers_pca[:, 1], \n",
        "           c='red', marker='X', s=200, edgecolors='black', linewidth=2,\n",
        "           label='Centroids')\n",
        "\n",
        "# Add cluster labels\n",
        "for i, (x, y) in enumerate(centers_pca):\n",
        "    plt.annotate(f'C{i}', (x, y), fontsize=12, fontweight='bold',\n",
        "                ha='center', va='center', color='white')\n",
        "\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Clean up - remove the cluster column if you want to keep original data intact\n",
        "X_kmeans = X_kmeans.drop('Cluster', axis=1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ac",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
